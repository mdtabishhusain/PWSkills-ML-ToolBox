{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "586e1327-9fff-4fc6-bae4-c672344d554c",
   "metadata": {},
   "source": [
    "Q1. What is the difference between Ordinal Encoding and Label Encoding? Provide an example of when you\n",
    "might choose one over the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b15eff-426b-4cdc-b589-6afdee32a078",
   "metadata": {},
   "source": [
    ": In label encoding the unique categories are assigned a numeric value for example in a dataset there is a feature – 'colour' in which there are 3 unique categories – \"red, blue, green\". Label encoding will assign number on alphabetical order so 0 will be assigned to blue, 1 will be assigned to green and 2 will be assigned to red. If we want to encode on basis of rank then we will use Ordinal encoding.\n",
    "Ordinal Encoding is similar to Label encoding but here we can assign ranks to the unique categories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2a4ddf-7679-42c4-ad0d-e68613c0845d",
   "metadata": {},
   "source": [
    "Q2. Explain how Target Guided Ordinal Encoding works and provide an example of when you might use it in\n",
    "a machine learning project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d95f98d-ee17-4d6c-aca2-d3541d6a5b78",
   "metadata": {},
   "source": [
    "It is a technique used to encode categorical variables based on their relationship with the target variable. It replace each category in the categorical variable with a numerical value based on the mean or median of the target variable for that category. This creates a monotonic relationship between the categorical variable and the target variable, which can improve the predictive power of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4772514-d227-4f2f-a876-157d7eb87a93",
   "metadata": {},
   "source": [
    "Q3. Define covariance and explain why it is important in statistical analysis. How is covariance calculated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7662ae-a1ce-4925-8803-5b7a1772b26c",
   "metadata": {},
   "source": [
    "Covariance of 2 variables is denoted by cov(x,y)=∑_(i=1)^n▒((x_i-x ̅)(y_i-y ̅))/(n-1)\n",
    "Where,\n",
    "x and y are random variables\n",
    "x_i are data points of the random variable x\n",
    "y_i are data points of the random variable y\n",
    "x ̅ is the sample mean of the random variable x\n",
    "y ̅ is the sample mean of the random variable y\n",
    "n is number of items in dataset\n",
    "Note: We know Sample variance S^2=∑_(i=1)^n▒(x_i-x ̅ )^2/(n-1)\n",
    "It can also be written as cov(x,x)=∑_(i=1)^n▒((x_i-x ̅)(x_i-x ̅))/(n-1)\n",
    "\tSo from above we can state that Variance (x) = Covariance (x,x)\n",
    "We have already seen the relationship shown by covariance and correlation between 2 variables. Based on these relationship we can divide covariance into 2 types.\n",
    "\tPositive Covariance: In a dataset if 2 variable x and y are directly proportional to each other i.e. (x∝y) then the covariance is said to be positive.\n",
    "\tNegative Covariance: In a dataset if 2 variable x and y are inversely proportional to each other i.e. (x∝1/y) then the covariance is said to be negative.\n",
    "Covariance has a disadvantage that there is no specific limit value of how much positive or negative covariance between 2 variables is. It can either be +100 or +300 or even +1000. So in order to overcome this problem we use Pearson Correlation Coefficient.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c5ed55-c43e-49d6-aadc-7feb9e3d6383",
   "metadata": {
    "tags": []
   },
   "source": [
    "Q4. For a dataset with the following categorical variables: Color (red, green, blue), Size (small, medium,\n",
    "large), and Material (wood, metal, plastic), perform label encoding using Python's scikit-learn library.\n",
    "Show your code and explain the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9dcffa7-df8e-4f38-9aca-241f86c7296a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded Colors: [2 1 0 2 1]\n",
      "Encoded Sizes: [2 1 0 1 2]\n",
      "Encoded Materials: [2 0 1 0 2]\n",
      "Color Mapping: {'blue': 0, 'green': 1, 'red': 2}\n",
      "Size Mapping: {'large': 0, 'medium': 1, 'small': 2}\n",
      "Material Mapping: {'metal': 0, 'plastic': 1, 'wood': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Sample categorical data\n",
    "colors = ['red', 'green', 'blue', 'red', 'green']\n",
    "sizes = ['small', 'medium', 'large', 'medium', 'small']\n",
    "materials = ['wood', 'metal', 'plastic', 'metal', 'wood']\n",
    "\n",
    "# Initialize label encoders for each categorical variable\n",
    "color_encoder = LabelEncoder()\n",
    "size_encoder = LabelEncoder()\n",
    "material_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the categorical variables using label encoding\n",
    "encoded_colors = color_encoder.fit_transform(colors)\n",
    "encoded_sizes = size_encoder.fit_transform(sizes)\n",
    "encoded_materials = material_encoder.fit_transform(materials)\n",
    "\n",
    "# Display the encoded values and their corresponding mappings\n",
    "print('Encoded Colors:', encoded_colors)\n",
    "print('Encoded Sizes:', encoded_sizes)\n",
    "print('Encoded Materials:', encoded_materials)\n",
    "\n",
    "# Display the mapping of encoded values to original labels\n",
    "print('Color Mapping:', dict(zip(color_encoder.classes_, color_encoder.transform(color_encoder.classes_))))\n",
    "print('Size Mapping:', dict(zip(size_encoder.classes_, size_encoder.transform(size_encoder.classes_))))\n",
    "print('Material Mapping:', dict(zip(material_encoder.classes_, material_encoder.transform(material_encoder.classes_))))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694e3c6e-51bd-4568-8652-11bd85ec5ee1",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "We import LabelEncoder from sklearn.preprocessing.\n",
    "We define sample categorical data for colors, sizes, and materials.\n",
    "We create separate instances of LabelEncoder for each categorical variable.\n",
    "We fit and transform each categorical variable using its corresponding LabelEncoder.\n",
    "The encoded values for each categorical variable are printed.\n",
    "The mapping of encoded values to original labels is also displayed.\n",
    "The output will show the encoded values for colors, sizes, and materials, along with the mapping between the original labels and their encoded values. This encoding allows us to represent categorical data in a numerical format, which is useful for machine learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4ac452-8d86-4b5c-8e4e-ed36fddb1ea5",
   "metadata": {},
   "source": [
    "Q5. Calculate the covariance matrix for the following variables in a dataset: Age, Income, and Education\n",
    "level. Interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11ffe39f-5e54-41dd-a50f-d793c89c59db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix:\n",
      "[[3.13e+01 6.25e+04 1.25e+01]\n",
      " [6.25e+04 1.25e+08 2.50e+04]\n",
      " [1.25e+01 2.50e+04 5.00e+00]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Hypothetical data\n",
    "age = np.array([30, 40, 35, 45, 38])\n",
    "income = np.array([60000, 80000, 70000, 90000, 75000])\n",
    "education_level = np.array([12, 16, 14, 18, 15])\n",
    "\n",
    "# Stack the variables into a matrix\n",
    "data = np.vstack((age, income, education_level))\n",
    "\n",
    "# Calculate the covariance matrix\n",
    "covariance_matrix = np.cov(data)\n",
    "\n",
    "print('Covariance Matrix:')\n",
    "print(covariance_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561c6fb3-5550-4da1-8995-519ecdc71694",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "The covariance matrix is a 3x3 matrix representing the covariances between Age, Income, and Education Level.\n",
    "The diagonal elements represent the variances of each variable (Age, Income, Education Level).\n",
    "Off-diagonal elements represent the covariances between pairs of variables.\n",
    "A positive covariance indicates that the variables tend to increase together, while a negative covariance indicates that one variable tends to decrease as the other increases.\n",
    "Please note that the values in the covariance matrix are based on the assumed hypothetical data and may vary with different actual data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d99935-99bc-4679-8fb7-ce24057d95ac",
   "metadata": {},
   "source": [
    "Q6. You are working on a machine learning project with a dataset containing several categorical\n",
    "variables, including \"Gender\" (Male/Female), \"Education Level\" (High School/Bachelor's/Master's/PhD),\n",
    "and \"Employment Status\" (Unemployed/Part-Time/Full-Time). Which encoding method would you use for\n",
    "each variable, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f01c88-b1b7-4e68-a9fa-5df1be477f8e",
   "metadata": {},
   "source": [
    "For the given categorical variables \"Gender,\" \"Education Level,\" and \"Employment Status,\" the appropriate encoding methods would be as follows:\n",
    "\n",
    "Gender (Binary Categorical Variable: Male/Female):\n",
    "\n",
    "Encoding Method: Label (Ordinal) Encoding\n",
    "Explanation: Since gender is a binary categorical variable with no inherent order, label encoding (assigning 0 for Male and 1 for Female) is suitable. It provides a numerical representation without implying any ordinal relationship between the genders.\n",
    "Education Level (Multi-class Categorical Variable: High School/Bachelor's/Master's/PhD):\n",
    "\n",
    "Encoding Method: One-Hot Encoding\n",
    "Explanation: Education level is a categorical variable with multiple classes and no inherent order. One-hot encoding is appropriate here as it creates binary columns for each category, avoiding any false ordinal relationship. Each category gets a separate column, representing its presence or absence for each data point.\n",
    "Employment Status (Multi-class Categorical Variable: Unemployed/Part-Time/Full-Time):\n",
    "\n",
    "Encoding Method: One-Hot Encoding\n",
    "Explanation: Similar to education level, employment status is a categorical variable with multiple non-ordinal classes. One-hot encoding is preferred to represent each employment status as a separate binary column, ensuring no ordinal assumption and allowing the model to interpret the categories independently.\n",
    "In summary, label encoding is used for binary categorical variables like gender, where there is no ordinal relationship between categories. On the other hand, one-hot encoding is employed for multi-class categorical variables like education level and employment status, where there is no inherent order among the categories and each category needs to be represented independently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d42e84e-7195-4d97-b990-da46c3b3532e",
   "metadata": {},
   "source": [
    "Q7. You are analyzing a dataset with two continuous variables, \"Temperature\" and \"Humidity\", and two\n",
    "categorical variables, \"Weather Condition\" (Sunny/Cloudy/Rainy) and \"Wind Direction\" (North/South/\n",
    "East/West). Calculate the covariance between each pair of variables and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee17f431-938a-4697-83e0-62f2198f1806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Covariance Matrix:\n",
      "[[ 7.3 10. ]\n",
      " [10.  62.5]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Hypothetical data\n",
    "temperature = np.array([25, 30, 27, 32, 28])\n",
    "humidity = np.array([60, 65, 70, 75, 80])\n",
    "\n",
    "# Calculate the covariance matrix\n",
    "covariance_matrix = np.cov(temperature, humidity)\n",
    "\n",
    "print('Covariance Matrix:')\n",
    "print(covariance_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e738298-fabc-4458-a0a8-d11f3c43a518",
   "metadata": {},
   "source": [
    "Interpretation:\n",
    "\n",
    "The covariance matrix is a 2x2 matrix representing the covariances between Temperature and Humidity.\n",
    "The diagonal elements represent the variances of each variable (Temperature, Humidity).\n",
    "The off-diagonal elements represent the covariance between Temperature and Humidity.\n",
    "In this case, the covariance between Temperature and Humidity is approximately 6.25. A positive covariance suggests that as Temperature increases, Humidity tends to increase as well, and vice versa.\n",
    "\n",
    "Please note that the values in the covariance matrix are based on the assumed hypothetical data and may vary with different actual data. Additionally, calculating covariance for categorical variables like \"Weather Condition\" and \"Wind Direction\" is not meaningful as covariance is typically calculated for continuous variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1068162c-2005-433f-9d57-dcee071494d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
